{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy using MLP classifier\n",
      "1.0\n",
      "confusion matrix\n",
      "[[36  0]\n",
      " [ 0 49]]\n",
      "the evaluation of the system interms of precision, recall and f1-score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        49\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "sdf=pd.read_excel(r'C:\\Users\\pc\\Documents\\chisquare\\feature\\three\\shuffle3.xlsx')\n",
    "sdf=sdf.loc[sdf.iloc[:,-1].isin([0,1])]\n",
    "X=sdf.iloc[:,:-1]\n",
    "Y=sdf.iloc[:,-1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(265), max_iter=1000) \n",
    "#mlp=KNeighborsClassifier(n_neighbors=5)\n",
    "mlp.fit(X_train,Y_train)  \n",
    "result=mlp.score(X_test,Y_test)\n",
    "print('classification accuracy using MLP classifier')\n",
    "print(result)\n",
    "predictions = mlp.predict(X_test) \n",
    "print(\"confusion matrix\")\n",
    "print(confusion_matrix(Y_test,predictions))  \n",
    "print(\"the evaluation of the system interms of precision, recall and f1-score\")\n",
    "print(classification_report(Y_test,predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten,Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf=pd.read_excel(r'C:\\Users\\pc\\Documents\\chisquare\\feature\\three\\shuffle3.xlsx')\n",
    "sdf=sdf.loc[sdf.iloc[:,-1].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 4.0124 - accuracy: 0.5199\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4474 - accuracy: 0.4658\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.5456\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.5944\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.6395\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.6780\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7792\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7235\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7819\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7802\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8079\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.9092\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8630\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.9365\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.9395\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022EDF0BDF78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "X=sdf.iloc[:,:-1]\n",
    "Y=sdf.iloc[:,-1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "count_classes = Y_test.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=747, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    " # Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=15)\n",
    "model.save(\"my_model.h5\")\n",
    "test_loss,test_acc=model.evaluate(X_test,  Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy using LSTM\n",
      "0.9882352948188782\n",
      "testing loss in LSTM\n",
      "0.31114256381988525\n"
     ]
    }
   ],
   "source": [
    "print(\"testing accuracy using LSTM\")\n",
    "print(test_acc)\n",
    "print(\"testing loss in LSTM\")\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0]\n",
      "[0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0]\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "Y_test=np.argmax(Y_test,axis=1)\n",
    "Y_pre = np.argmax(loaded_model.predict(X_test),axis=1)\n",
    "print(Y_pre)\n",
    "print(Y_test)\n",
    "precision=precision_score(Y_test, Y_pre)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0]\n",
      "[0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(Y_pre)\n",
    "print(Y_test)\n",
    "recall= recall_score(Y_test, Y_pre)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0]\n",
      "[0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0]\n",
      "0.98989898989899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(Y_pre)\n",
    "print(Y_test)\n",
    "recall= f1_score(Y_test, Y_pre)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
